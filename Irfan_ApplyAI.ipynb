{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e1664c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, scale, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import librosa, librosa.display, os, csv\n",
    "import matplotlib\n",
    "import pylab\n",
    "plt.switch_backend('agg')\n",
    "import itertools\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import joblib\n",
    "from glob import glob\n",
    "import urllib\n",
    "\n",
    "# internal imports\n",
    "from utils import preproces, CoughNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f69211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 170\n",
      "Number of positive examples: 19\n",
      "Number of negative examples: 151\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_properties</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0v8MGxNetjg_ 10.000_ 20.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1j1duoxdxBg_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MSYO4wgiag_ 120.000_ 130.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1PajbAKd8Kg_ 0.000_ 10.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cov1.wav</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-bZrDCS8KAg_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-ej81N6Aqo4_ 0.000_ 8.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-gvLnl1smfs_ 90.000_ 100.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-hu5q-Nn4BM_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-jLQkyDhIxw_ 10.000_ 20.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_properties      class\n",
       "0      0v8MGxNetjg_ 10.000_ 20.000.wav  not_covid\n",
       "1      1j1duoxdxBg_ 70.000_ 80.000.wav  not_covid\n",
       "2    1MSYO4wgiag_ 120.000_ 130.000.wav  not_covid\n",
       "3       1PajbAKd8Kg_ 0.000_ 10.000.wav  not_covid\n",
       "4                             cov1.wav      covid\n",
       "..                                 ...        ...\n",
       "165    -bZrDCS8KAg_ 70.000_ 80.000.wav  not_covid\n",
       "166      -ej81N6Aqo4_ 0.000_ 8.000.wav  not_covid\n",
       "167   -gvLnl1smfs_ 90.000_ 100.000.wav  not_covid\n",
       "168    -hu5q-Nn4BM_ 70.000_ 80.000.wav  not_covid\n",
       "169    -jLQkyDhIxw_ 10.000_ 20.000.wav  not_covid\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle Dataset - Exploration\n",
    "fn_dataset = 'data/cough_trial_extended.csv'\n",
    "df_dataset = pd.read_csv(fn_dataset)\n",
    "\n",
    "print('Total number of examples:', len(df_dataset))\n",
    "print('Number of positive examples:', len(df_dataset[df_dataset['class'] == 'covid']))\n",
    "print('Number of negative examples:', len(df_dataset[df_dataset['class'] == 'not_covid']))\n",
    "\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "029b1d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2c854b694f4e49a654b2f0a0313a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0v8MGxNetjg_ 10.000_ 20.000.wav</td>\n",
       "      <td>0.519951</td>\n",
       "      <td>0.045853</td>\n",
       "      <td>1612.895795</td>\n",
       "      <td>1411.838677</td>\n",
       "      <td>2907.580566</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>-376.876007</td>\n",
       "      <td>111.017372</td>\n",
       "      <td>-31.904015</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.439712</td>\n",
       "      <td>-1.034580</td>\n",
       "      <td>-0.203083</td>\n",
       "      <td>-3.513495</td>\n",
       "      <td>-1.745705</td>\n",
       "      <td>-3.011878</td>\n",
       "      <td>-2.878482</td>\n",
       "      <td>-2.106427</td>\n",
       "      <td>-4.026825</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1j1duoxdxBg_ 70.000_ 80.000.wav</td>\n",
       "      <td>0.535472</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>2892.087076</td>\n",
       "      <td>2467.408141</td>\n",
       "      <td>5072.664388</td>\n",
       "      <td>0.148584</td>\n",
       "      <td>-519.158447</td>\n",
       "      <td>60.781284</td>\n",
       "      <td>-13.722886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.909973</td>\n",
       "      <td>7.216461</td>\n",
       "      <td>-1.719629</td>\n",
       "      <td>3.903021</td>\n",
       "      <td>3.653039</td>\n",
       "      <td>3.043882</td>\n",
       "      <td>2.439957</td>\n",
       "      <td>2.781968</td>\n",
       "      <td>2.195162</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MSYO4wgiag_ 120.000_ 130.000.wav</td>\n",
       "      <td>0.496666</td>\n",
       "      <td>0.033657</td>\n",
       "      <td>3429.061935</td>\n",
       "      <td>2788.634413</td>\n",
       "      <td>6886.288452</td>\n",
       "      <td>0.225315</td>\n",
       "      <td>-282.297913</td>\n",
       "      <td>48.581680</td>\n",
       "      <td>-15.522366</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.066336</td>\n",
       "      <td>-4.167640</td>\n",
       "      <td>1.017302</td>\n",
       "      <td>-0.523806</td>\n",
       "      <td>0.538693</td>\n",
       "      <td>-8.855953</td>\n",
       "      <td>-2.927977</td>\n",
       "      <td>-1.118562</td>\n",
       "      <td>-5.906228</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1PajbAKd8Kg_ 0.000_ 10.000.wav</td>\n",
       "      <td>0.407549</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>2710.811637</td>\n",
       "      <td>2664.287550</td>\n",
       "      <td>5778.474935</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>-346.857300</td>\n",
       "      <td>75.765617</td>\n",
       "      <td>-7.648194</td>\n",
       "      <td>...</td>\n",
       "      <td>5.053118</td>\n",
       "      <td>-0.291308</td>\n",
       "      <td>0.987186</td>\n",
       "      <td>-2.447526</td>\n",
       "      <td>3.692367</td>\n",
       "      <td>2.312328</td>\n",
       "      <td>-2.059656</td>\n",
       "      <td>-4.772599</td>\n",
       "      <td>-0.503851</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cov1.wav</td>\n",
       "      <td>0.412697</td>\n",
       "      <td>0.059004</td>\n",
       "      <td>1555.648634</td>\n",
       "      <td>1418.599932</td>\n",
       "      <td>2870.737092</td>\n",
       "      <td>0.133998</td>\n",
       "      <td>-340.588013</td>\n",
       "      <td>104.156700</td>\n",
       "      <td>-32.228443</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.247168</td>\n",
       "      <td>0.940006</td>\n",
       "      <td>-5.701087</td>\n",
       "      <td>-6.326630</td>\n",
       "      <td>-1.080040</td>\n",
       "      <td>-1.812609</td>\n",
       "      <td>-2.518986</td>\n",
       "      <td>-3.684266</td>\n",
       "      <td>-3.564146</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filename  chroma_stft      rmse  \\\n",
       "0    0v8MGxNetjg_ 10.000_ 20.000.wav     0.519951  0.045853   \n",
       "1    1j1duoxdxBg_ 70.000_ 80.000.wav     0.535472  0.001771   \n",
       "2  1MSYO4wgiag_ 120.000_ 130.000.wav     0.496666  0.033657   \n",
       "3     1PajbAKd8Kg_ 0.000_ 10.000.wav     0.407549  0.013452   \n",
       "4                           cov1.wav     0.412697  0.059004   \n",
       "\n",
       "   spectral_centroid  spectral_bandwidth      rolloff  zero_crossing_rate  \\\n",
       "0        1612.895795         1411.838677  2907.580566            0.107019   \n",
       "1        2892.087076         2467.408141  5072.664388            0.148584   \n",
       "2        3429.061935         2788.634413  6886.288452            0.225315   \n",
       "3        2710.811637         2664.287550  5778.474935            0.142076   \n",
       "4        1555.648634         1418.599932  2870.737092            0.133998   \n",
       "\n",
       "        mfcc1       mfcc2      mfcc3  ...    mfcc12    mfcc13    mfcc14  \\\n",
       "0 -376.876007  111.017372 -31.904015  ... -7.439712 -1.034580 -0.203083   \n",
       "1 -519.158447   60.781284 -13.722886  ... -0.909973  7.216461 -1.719629   \n",
       "2 -282.297913   48.581680 -15.522366  ... -6.066336 -4.167640  1.017302   \n",
       "3 -346.857300   75.765617  -7.648194  ...  5.053118 -0.291308  0.987186   \n",
       "4 -340.588013  104.156700 -32.228443  ... -8.247168  0.940006 -5.701087   \n",
       "\n",
       "     mfcc15    mfcc16    mfcc17    mfcc18    mfcc19    mfcc20      label  \n",
       "0 -3.513495 -1.745705 -3.011878 -2.878482 -2.106427 -4.026825  not_covid  \n",
       "1  3.903021  3.653039  3.043882  2.439957  2.781968  2.195162  not_covid  \n",
       "2 -0.523806  0.538693 -8.855953 -2.927977 -1.118562 -5.906228  not_covid  \n",
       "3 -2.447526  3.692367  2.312328 -2.059656 -4.772599 -0.503851  not_covid  \n",
       "4 -6.326630 -1.080040 -1.812609 -2.518986 -3.684266 -3.564146      covid  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle Dataset - Feature Extraction\n",
    "df_features_cols = ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate']\n",
    "for i in range(1, 21):\n",
    "    df_features_cols.append(f'mfcc{i}')\n",
    "df_features_cols.append('label')\n",
    "\n",
    "df_features = pd.DataFrame(columns=df_features_cols)\n",
    "\n",
    "for row_index, row in tqdm(df_dataset.iterrows(), total=len(df_dataset)):\n",
    "    fn_wav = os.path.join('data/trial_covid/', row['file_properties'])\n",
    "    feature_row = preproces(fn_wav)\n",
    "    feature_row['filename'] = row['file_properties']\n",
    "    feature_row['label'] = row['class']\n",
    "    df_features = df_features.append(feature_row, ignore_index=True)\n",
    "\n",
    "df_features.to_csv('data/prepared_data_kaggle.csv', index=False, columns=df_features_cols)\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c85ff9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 121\n",
      "Number of positive examples: 48\n",
      "Number of negative examples: 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_properties</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/virufy/pos\\pos-0421-084-cough-m-50-0.mp3</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/virufy/pos\\pos-0421-084-cough-m-50-1.mp3</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/virufy/pos\\pos-0421-084-cough-m-50-2.mp3</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/virufy/pos\\pos-0421-084-cough-m-50-3.mp3</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/virufy/pos\\pos-0421-084-cough-m-50-4.mp3</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>data/virufy/neg\\neg-0422-097-cough-m-37-8.mp3</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>data/virufy/neg\\neg-0422-097-cough-m-37-9.mp3</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>data/virufy/neg\\neg-0422-098-cough-f-24-0.mp3</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>data/virufy/neg\\neg-0422-098-cough-f-24-1.mp3</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>data/virufy/neg\\neg-0422-098-cough-f-24-5.mp3</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file_properties      class\n",
       "0    data/virufy/pos\\pos-0421-084-cough-m-50-0.mp3      covid\n",
       "1    data/virufy/pos\\pos-0421-084-cough-m-50-1.mp3      covid\n",
       "2    data/virufy/pos\\pos-0421-084-cough-m-50-2.mp3      covid\n",
       "3    data/virufy/pos\\pos-0421-084-cough-m-50-3.mp3      covid\n",
       "4    data/virufy/pos\\pos-0421-084-cough-m-50-4.mp3      covid\n",
       "..                                             ...        ...\n",
       "116  data/virufy/neg\\neg-0422-097-cough-m-37-8.mp3  not_covid\n",
       "117  data/virufy/neg\\neg-0422-097-cough-m-37-9.mp3  not_covid\n",
       "118  data/virufy/neg\\neg-0422-098-cough-f-24-0.mp3  not_covid\n",
       "119  data/virufy/neg\\neg-0422-098-cough-f-24-1.mp3  not_covid\n",
       "120  data/virufy/neg\\neg-0422-098-cough-f-24-5.mp3  not_covid\n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Virufy Dataset - Exploration\n",
    "import glob\n",
    "df_dataset = pd.DataFrame(columns=['file_properties', 'class'])\n",
    "for fn in glob.glob('data/virufy/pos/*.mp3'):\n",
    "    df_dataset = df_dataset.append({'file_properties': fn, 'class': 'covid'}, ignore_index=True)\n",
    "for fn in glob.glob('data/virufy/neg/*.mp3'):\n",
    "    df_dataset = df_dataset.append({'file_properties': fn, 'class': 'not_covid'}, ignore_index=True)\n",
    "\n",
    "print('Total number of examples:', len(df_dataset))\n",
    "print('Number of positive examples:', len(df_dataset[df_dataset['class'] == 'covid']))\n",
    "print('Number of negative examples:', len(df_dataset[df_dataset['class'] == 'not_covid']))\n",
    "\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469d9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Virufy Dataset - Feature Extraction\n",
    "#df_features_cols = ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate']\n",
    "#for i in range(1, 21):\n",
    "    #df_features_cols.append(f'mfcc{i}')\n",
    "#df_features_cols.append('label')\n",
    "\n",
    "#df_features = pd.DataFrame(columns=df_features_cols)\n",
    "\n",
    "#for row_index, row in tqdm(df_dataset.iterrows(), total=len(df_dataset)):\n",
    "    #fn_wav = os.path.join('data/virufy/pos/*.mp3', row['file_properties'])\n",
    "    #fn_wav = row['file_properties']\n",
    "    #feature_row = preproces(fn_wav)\n",
    "    #feature_row['filename'] = row['file_properties']\n",
    "    #feature_row['label'] = row['class']\n",
    "    #df_features = df_features.append(feature_row, ignore_index=True)\n",
    "\n",
    "#df_features.to_csv('data/prepared_data_virufy.csv', index=False, columns=df_features_cols)\n",
    "\n",
    "#df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ada2d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 291\n",
      "Number of positive examples: 67\n",
      "Number of negative examples: 224\n"
     ]
    }
   ],
   "source": [
    "#Combine Datasets\n",
    "df_features_kaggle = pd.read_csv('data/prepared_data_kaggle.csv')\n",
    "df_features_virufy = pd.read_csv('data/prepared_data_virufy.csv')\n",
    "df_features = pd.concat([df_features_kaggle, df_features_virufy])\n",
    "\n",
    "df_features.to_csv('data/prepared_data.csv', index=False, columns=df_features_cols)\n",
    "\n",
    "print('Total number of examples:', len(df_features))\n",
    "print('Number of positive examples:', len(df_features[df_features['label'] == 'covid']))\n",
    "print('Number of negative examples:', len(df_features[df_features['label'] == 'not_covid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2162b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 134\n",
      "Number of positive examples: 67\n",
      "Number of negative examples: 67\n"
     ]
    }
   ],
   "source": [
    "#Balanced Dataset\n",
    "df_features = pd.read_csv('data/prepared_data.csv')\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_features[df_features['label'] == 'not_covid']\n",
    "df_minority = df_features[df_features['label'] == 'covid']\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_balanced = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_balanced = pd.concat([df_majority_balanced, df_minority])\n",
    "\n",
    "df_balanced.to_csv('data/prepared_data_balanced.csv', index=False)\n",
    "\n",
    "print('Total number of examples:', len(df_balanced))\n",
    "print('Number of positive examples:', len(df_balanced[df_balanced['label'] == 'covid']))\n",
    "print('Number of negative examples:', len(df_balanced[df_balanced['label'] == 'not_covid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85fb5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Evaluation\n",
    "# system imports\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# internal imports\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a7e285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "hparams = {    \n",
    "    'dataset': 'data/prepared_data_balanced.csv',\n",
    "    'epochs': 15,\n",
    "    'batch_size': 16,\n",
    "    'lr': 1e-3,\n",
    "    'features': [\n",
    "        'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate',\n",
    "        'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', \n",
    "        'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6d3e7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['covid' 'not_covid']\n",
      "X_train.shape: (107, 26)\n",
      "y_train.shape: (107,)\n"
     ]
    }
   ],
   "source": [
    "#Prepare Data\n",
    "df_features = pd.read_csv(hparams['dataset'])\n",
    "\n",
    "X = np.array(df_features[hparams['features']], dtype=np.float32)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df_features['label'])\n",
    "print('classes:', encoder.classes_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "\n",
    "# create pytorch dataloader\n",
    "torch.manual_seed(42)\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train).long())\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test).long())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=hparams['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f4c3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Model\n",
    "# Design model (input, output size, forward pass)\n",
    "class CoughNet(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CoughNet, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(input_size, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "        self.l6 = torch.nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x = torch.relu(self.l2(x))\n",
    "        x = torch.relu(self.l3(x))\n",
    "        x = torch.relu(self.l4(x))\n",
    "        x = torch.relu(self.l5(x))\n",
    "        x = self.l6(x)\n",
    "        return x\n",
    "\n",
    "model = CoughNet(len(hparams['features'])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b479cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974dc0539cb849b0a2ed11861d486994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9cdc6529f5478fa024097aa393eb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c265bec7d1d47f2a1ac5f2c5510fcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ddc668834408e9a5d99aae24e7a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f789adceb3e24cacbb465d176e4a8bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f19c8b367249d49992422e898a4c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9157499ddb9f481b96b37c3a154cc818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d2686193334c2ca83ffcb25a017e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1a3c99f32a4385a6984e5148503bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77cb2df096e4b7eb7386d217ac8f66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7815d763da64c318d7870f8876b0801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d0061c22c84c4b9facf4b49b941692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6759f5ba368c40c28a8d4b0960802b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d0e18bcf1449b4bda16e7e1c506b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5be026c3b94fa498e40855e8eb99a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4255aa7f2847269395164cf4137258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5e759f93684fc8857b678b7e24a5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93f4f2f6ca44f97802417b71b04a24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e0916ca8a24035af2f4586c817ff9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cabdd33733d44b38a7af83d73a85fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82a02f9447541db9f6313494f655b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bc19540ac14b3fb04e57ed5e35296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535aefdeeb7a4fc782260edb6313ddf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31269ba3b2544f30a36e43553286e1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf870fbf01c429780dec67d01302baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd4084c53504e709b75e57ef9d22592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc0c65fce2c472f91fc954d12d28133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775e2270b04142f0818e4e3a9cd0fd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377ca08ff2dc4256bd00695d9947bf87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680dd1ef3f214de2b2903d6ff1c30983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training\n",
    "# Construct loss and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['lr'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(loader_train, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(loader_train), total=len(loader_train))\n",
    "    for batch_ndx, sample in pbar: \n",
    "        features, labels = sample[0].to(device), sample[1].to(device) \n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)  \n",
    "        \n",
    "        # backward pass    \n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate metrics\n",
    "        running_loss += loss.item()\n",
    "        predictions = torch.argmax(outputs.data, 1)\n",
    "        running_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        # print informations\n",
    "        pbar.set_description(f'[Training Epoch {epoch+1}]') \n",
    "        total += labels.shape[0]\n",
    "        pbar.set_postfix({'loss': running_loss / total, 'train_accuracy': running_correct / total})\n",
    "        \n",
    "    # write informations to tensorboard\n",
    "    writer.add_scalar('Loss/Train', running_loss / total, epoch+1)\n",
    "    writer.add_scalar('Accuracy/Train', running_correct / total, epoch+1)\n",
    "\n",
    "def evaluate(loader_test, model, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(loader_test), total=len(loader_test))\n",
    "        for batch_ndx, sample in pbar:\n",
    "            features, labels = sample[0].to(device), sample[1].to(device) \n",
    "\n",
    "            # forward pass and loss calculation\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)  \n",
    "\n",
    "            # calculate metrics\n",
    "            running_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs.data, 1)\n",
    "            running_correct += (predictions == labels).sum().item()\n",
    "\n",
    "            # print informations\n",
    "            pbar.set_description(f'[Evaluating Epoch {epoch+1}]')\n",
    "            total += labels.shape[0]\n",
    "            pbar.set_postfix({'loss': running_loss / total, 'eval_accuracy': running_correct / total})\n",
    "        \n",
    "    # write informations to tensorboard\n",
    "    writer.add_scalar('Loss/Eval', running_loss / total, epoch+1)\n",
    "    writer.add_scalar('Accuracy/Eval', running_correct / total, epoch+1)\n",
    "\n",
    "# initialize tensorboard summary writer\n",
    "time_stamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "writer = SummaryWriter(f'logs/{time_stamp}/')\n",
    "\n",
    "# add graph to tensorboard\n",
    "features = iter(test_loader).next()[0]\n",
    "writer.add_graph(model, features)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(hparams['epochs']):\n",
    "    train(train_loader, model, optimizer, epoch)\n",
    "    evaluate(test_loader, model, epoch)\n",
    "\n",
    "# close tensorboard\n",
    "writer.close()\n",
    "\n",
    "# open tensorboard\n",
    "# tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ffc54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrix\n",
    "# internal imports\n",
    "from utils import plot_confusion_matrix\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch.tensor(X_test))\n",
    "    predictions = torch.argmax(outputs.data, 1)\n",
    "\n",
    "plot_confusion_matrix(y_test, predictions, encoder.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65d32197",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'hparams': hparams,\n",
    "    'model_state': model.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder\n",
    "}\n",
    "torch.save(checkpoint, 'data/checkpoints/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6c2a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to test file\n",
    "fn_wav = 'data/test.wav' # positive example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4e07afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model outputs [9.9903202e-01 9.6800784e-04] which predicts the class covid!\n"
     ]
    }
   ],
   "source": [
    "#Inference\n",
    "# load model from checkpoint\n",
    "loaded_checkpoint = torch.load('data/checkpoints/checkpoint.pth')\n",
    "\n",
    "hparams = loaded_checkpoint['hparams']\n",
    "scaler = loaded_checkpoint['scaler']\n",
    "encoder = loaded_checkpoint['encoder']\n",
    "\n",
    "model = CoughNet(len(hparams['features']))\n",
    "model.eval()\n",
    "model.load_state_dict(loaded_checkpoint['model_state'])\n",
    "\n",
    "# create input features\n",
    "df_features = pd.DataFrame(columns=hparams['features'])\n",
    "df_features = df_features.append(preproces(fn_wav), ignore_index=True)\n",
    "X = np.array(df_features[hparams['features']], dtype=np.float32)\n",
    "X = torch.Tensor(scaler.transform(X))\n",
    "\n",
    "outputs = torch.softmax(model(X), 1)\n",
    "predictions = torch.argmax(outputs.data, 1)\n",
    "\n",
    "# print result\n",
    "print(f'model outputs {outputs[0].detach().numpy()} which predicts the class {encoder.classes_[predictions]}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ff74a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-Fold Cross Validation\n",
    "# system imports\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# additional imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# internal imports\n",
    "from utils import plot_confusion_matrix\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e02c632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "hparams = {    \n",
    "    'dataset': 'data/prepared_data_balanced.csv',\n",
    "    'epochs': 20,\n",
    "    'batch_size': 16,\n",
    "    'lr': 1e-3,\n",
    "    'features': [\n",
    "        'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate',\n",
    "        'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', \n",
    "        'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9aab3ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Data\n",
    "df_features = pd.read_csv(hparams['dataset'])\n",
    "X = np.array(df_features[hparams['features']], dtype=np.float32)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df_features['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02ea9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD CROSS VALIDATION RESULTS FOR 8 FOLDS\n",
      "--------------------------------------------\n",
      "|         | Train Accuracy | Test Accuracy |\n",
      "--------------------------------------------\n",
      "| Fold 0  |       100.00 % |       94.12 % |\n",
      "| Fold 1  |       100.00 % |       88.24 % |\n",
      "| Fold 2  |       100.00 % |       94.12 % |\n",
      "| Fold 3  |       100.00 % |       76.47 % |\n",
      "| Fold 4  |       100.00 % |       88.24 % |\n",
      "| Fold 5  |       100.00 % |       94.12 % |\n",
      "| Fold 6  |       100.00 % |       100.00 % |\n",
      "| Fold 7  |       96.61 % |       87.50 % |\n",
      "--------------------------------------------\n",
      "| Average |       99.58 % |       90.35 % |\n"
     ]
    }
   ],
   "source": [
    "#K-fold Cross Validation model evaluation\n",
    "k_folds = 8\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "indices = np.arange(len(y))\n",
    "results_train = []\n",
    "results_test = []\n",
    "\n",
    "def train(loader_train, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_correct = 0.0\n",
    "    total = 0\n",
    "    for batch_ndx, sample in enumerate(loader_train): \n",
    "        features, labels = sample[0].to(device), sample[1].to(device) \n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)  \n",
    "        \n",
    "        # backward pass    \n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate metrics\n",
    "        predictions = torch.argmax(outputs.data, 1)\n",
    "        running_correct += (predictions == labels).sum().item()\n",
    "        total += labels.shape[0]\n",
    "\n",
    "    return running_correct / total\n",
    "\n",
    "def evaluate(loader_test, model, epoch):\n",
    "    model.eval()\n",
    "    running_correct = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_ndx, sample in enumerate(loader_test):\n",
    "            features, labels = sample[0].to(device), sample[1].to(device) \n",
    "\n",
    "            # forward pass and loss calculation\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)  \n",
    "\n",
    "            # calculate metrics\n",
    "            predictions = torch.argmax(outputs.data, 1)\n",
    "            running_correct += (predictions == labels).sum().item()\n",
    "            total += labels.shape[0]\n",
    "\n",
    "    return running_correct / total\n",
    "\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------------------')\n",
    "print('|         | Train Accuracy | Test Accuracy |')\n",
    "print('--------------------------------------------')\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(indices)):\n",
    "    X_train = X[train_ids]\n",
    "    y_train = y[train_ids]\n",
    "    X_test = X[test_ids]\n",
    "    y_test = y[test_ids]\n",
    "    \n",
    "    # scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # create pytorch dataloader\n",
    "    torch.manual_seed(42)\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train).long())\n",
    "    test_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test).long())\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=hparams['batch_size'], shuffle=False)\n",
    "    \n",
    "    # create model\n",
    "    model = CoughNet(len(hparams['features'])).to(device)\n",
    "\n",
    "    # Construct loss and optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hparams['lr'])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(hparams['epochs']):\n",
    "        train_accuracy = train(train_loader, model, optimizer, epoch)\n",
    "        eval_accuracy = evaluate(test_loader, model, epoch)\n",
    "    results_train.append(train_accuracy) \n",
    "    results_test.append(eval_accuracy) \n",
    "    print(f'| Fold {fold}  |       {train_accuracy*100:.2f} % |       {eval_accuracy*100:.2f} % |')\n",
    "\n",
    "print('--------------------------------------------')\n",
    "print(f'| Average |       {np.mean(results_train)*100:.2f} % |       {np.mean(results_test)*100:.2f} % |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4bfba3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['covid' 'not_covid']\n",
      "X_train.shape: (107, 26)\n",
      "y_train.shape: (107,)\n"
     ]
    }
   ],
   "source": [
    "#Training and Evaluation\n",
    "#Prepare Data\n",
    "df_features = pd.read_csv(hparams['dataset'])\n",
    "\n",
    "X = np.array(df_features[hparams['features']], dtype=np.float32)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df_features['label'])\n",
    "print('classes:', encoder.classes_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('X_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90ba43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_classifier(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_train)\n",
    "    accuracy_train = np.sum(predictions == y_train) / len(y_train)\n",
    "    print(\"Train Accuracy:\", accuracy_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy_test = np.sum(predictions == y_test) / len(y_test)\n",
    "    print(\"Test Accuracy:\", accuracy_test)\n",
    "\n",
    "    plot_confusion_matrix(y_test, predictions, encoder.classes_)\n",
    "\n",
    "def k_fold_train_eval_classifier(clf):    \n",
    "    k_folds = 4\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    indices = np.arange(len(y))\n",
    "\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------------------')\n",
    "    print('|         | Train Accuracy | Test Accuracy |')\n",
    "    print('--------------------------------------------')\n",
    "\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(indices)):\n",
    "        X_train = X[train_ids]\n",
    "        y_train = y[train_ids]\n",
    "        X_test = X[test_ids]\n",
    "        y_test = y[test_ids]\n",
    "\n",
    "        # train classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # evaluate classifier on train dataset\n",
    "        predictions = clf.predict(X_train)\n",
    "        train_accuracy = np.sum(predictions == y_train) / len(y_train)\n",
    "        results_train.append(train_accuracy) \n",
    "\n",
    "        # evaluate classifier on test dataset\n",
    "        predictions = clf.predict(X_test)\n",
    "        eval_accuracy = np.sum(predictions == y_test) / len(y_test)        \n",
    "        results_test.append(eval_accuracy) \n",
    "\n",
    "        print(f'| Fold {fold}  |       {train_accuracy*100:.2f} % |       {eval_accuracy*100:.2f} % |')\n",
    "\n",
    "    print('--------------------------------------------')\n",
    "    print(f'| Average |       {np.mean(results_train)*100:.2f} % |       {np.mean(results_test)*100:.2f} % |')\n",
    "    \n",
    "    plot_confusion_matrix(y_test, predictions, encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f64f56b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD CROSS VALIDATION RESULTS FOR 4 FOLDS\n",
      "--------------------------------------------\n",
      "|         | Train Accuracy | Test Accuracy |\n",
      "--------------------------------------------\n",
      "| Fold 0  |       80.00 % |       70.59 % |\n",
      "| Fold 1  |       80.00 % |       61.76 % |\n",
      "| Fold 2  |       74.26 % |       87.88 % |\n",
      "| Fold 3  |       73.27 % |       81.82 % |\n",
      "--------------------------------------------\n",
      "| Average |       76.88 % |       75.51 % |\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "k_fold_train_eval_classifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5806af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD CROSS VALIDATION RESULTS FOR 4 FOLDS\n",
      "--------------------------------------------\n",
      "|         | Train Accuracy | Test Accuracy |\n",
      "--------------------------------------------\n",
      "| Fold 0  |       86.00 % |       73.53 % |\n",
      "| Fold 1  |       79.00 % |       70.59 % |\n",
      "| Fold 2  |       80.20 % |       63.64 % |\n",
      "| Fold 3  |       78.22 % |       84.85 % |\n",
      "--------------------------------------------\n",
      "| Average |       80.85 % |       73.15 % |\n"
     ]
    }
   ],
   "source": [
    "#Support Verctor Machine\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.NuSVC(kernel='poly')\n",
    "k_fold_train_eval_classifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00b98892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD CROSS VALIDATION RESULTS FOR 4 FOLDS\n",
      "--------------------------------------------\n",
      "|         | Train Accuracy | Test Accuracy |\n",
      "--------------------------------------------\n",
      "| Fold 0  |       100.00 % |       82.35 % |\n",
      "| Fold 1  |       100.00 % |       76.47 % |\n",
      "| Fold 2  |       100.00 % |       90.91 % |\n",
      "| Fold 3  |       100.00 % |       87.88 % |\n",
      "--------------------------------------------\n",
      "| Average |       100.00 % |       84.40 % |\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, n_estimators=100, random_state=42)\n",
    "k_fold_train_eval_classifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b40b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88936a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_properties</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0v8MGxNetjg_ 10.000_ 20.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1j1duoxdxBg_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1MSYO4wgiag_ 120.000_ 130.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1PajbAKd8Kg_ 0.000_ 10.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cov1.wav</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-bZrDCS8KAg_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-ej81N6Aqo4_ 0.000_ 8.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-gvLnl1smfs_ 90.000_ 100.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-hu5q-Nn4BM_ 70.000_ 80.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-jLQkyDhIxw_ 10.000_ 20.000.wav</td>\n",
       "      <td>not_covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_properties      class\n",
       "0      0v8MGxNetjg_ 10.000_ 20.000.wav  not_covid\n",
       "1      1j1duoxdxBg_ 70.000_ 80.000.wav  not_covid\n",
       "2    1MSYO4wgiag_ 120.000_ 130.000.wav  not_covid\n",
       "3       1PajbAKd8Kg_ 0.000_ 10.000.wav  not_covid\n",
       "4                             cov1.wav      covid\n",
       "..                                 ...        ...\n",
       "165    -bZrDCS8KAg_ 70.000_ 80.000.wav  not_covid\n",
       "166      -ej81N6Aqo4_ 0.000_ 8.000.wav  not_covid\n",
       "167   -gvLnl1smfs_ 90.000_ 100.000.wav  not_covid\n",
       "168    -hu5q-Nn4BM_ 70.000_ 80.000.wav  not_covid\n",
       "169    -jLQkyDhIxw_ 10.000_ 20.000.wav  not_covid\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Artificial NeuralNetwork with RELU Activation\n",
    "#Loading CSV file\n",
    "train_csv = pd.read_csv(\"data/cough_trial_extended.csv\")\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e26963dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not_covid', 'covid'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b463f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "tot_rows = train_csv.shape[0]\n",
    "for i in range(tot_rows):\n",
    "    source = train_csv['file_properties'][i]\n",
    "    filename = 'data/trial_covid/'+source\n",
    "    y,sr = librosa.load(filename, mono=True, duration=5)\n",
    "    plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "    plt.axis('off');\n",
    "    #plt.savefig(f'./{source[:-3].replace(\".\", \"\")}.png')\n",
    "    #plt.savefig(f'data/plot/{source[:-3].replace(\".\", \"\")}.png')\n",
    "    plt.show()\n",
    "    #plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a7b1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26ff5c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename',\n",
       " 'chroma_stft',\n",
       " 'rmse',\n",
       " 'spectral_centroid',\n",
       " 'spectral_bandwidth',\n",
       " 'rolloff',\n",
       " 'zero_crossing_rate',\n",
       " 'mfcc1',\n",
       " 'mfcc2',\n",
       " 'mfcc3',\n",
       " 'mfcc4',\n",
       " 'mfcc5',\n",
       " 'mfcc6',\n",
       " 'mfcc7',\n",
       " 'mfcc8',\n",
       " 'mfcc9',\n",
       " 'mfcc10',\n",
       " 'mfcc11',\n",
       " 'mfcc12',\n",
       " 'mfcc13',\n",
       " 'mfcc14',\n",
       " 'mfcc15',\n",
       " 'mfcc16',\n",
       " 'mfcc17',\n",
       " 'mfcc18',\n",
       " 'mfcc19',\n",
       " 'mfcc20',\n",
       " 'label']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66503b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/data_new_extended.csv', 'w')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for i in range(tot_rows):\n",
    "        source = train_csv['file_properties'][i]\n",
    "        file_name = 'data/trial_covid/'+source\n",
    "        y,sr = librosa.load(file_name, mono=True, duration=5)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{source[:-3].replace(\".\", \"\")} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        \n",
    "        file = open('data/data_new_extended.csv', 'a')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f723844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0v8MGxNetjg_</th>\n",
       "      <td>10000_</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>0.519951</td>\n",
       "      <td>0.045853</td>\n",
       "      <td>1612.895795</td>\n",
       "      <td>1411.838677</td>\n",
       "      <td>2907.580566</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>-376.876007</td>\n",
       "      <td>111.017372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656475</td>\n",
       "      <td>-7.439712</td>\n",
       "      <td>-1.034580</td>\n",
       "      <td>-0.203083</td>\n",
       "      <td>-3.513495</td>\n",
       "      <td>-1.745705</td>\n",
       "      <td>-3.011878</td>\n",
       "      <td>-2.878482</td>\n",
       "      <td>-2.106427</td>\n",
       "      <td>-4.026825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1j1duoxdxBg_</th>\n",
       "      <td>70000_</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>0.535472</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>2892.087076</td>\n",
       "      <td>2467.408141</td>\n",
       "      <td>5072.664388</td>\n",
       "      <td>0.148584</td>\n",
       "      <td>-519.158447</td>\n",
       "      <td>60.781284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156307</td>\n",
       "      <td>-0.909973</td>\n",
       "      <td>7.216461</td>\n",
       "      <td>-1.719629</td>\n",
       "      <td>3.903021</td>\n",
       "      <td>3.653039</td>\n",
       "      <td>3.043882</td>\n",
       "      <td>2.439957</td>\n",
       "      <td>2.781968</td>\n",
       "      <td>2.195162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1MSYO4wgiag_</th>\n",
       "      <td>120000_</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>0.496666</td>\n",
       "      <td>0.033657</td>\n",
       "      <td>3429.061935</td>\n",
       "      <td>2788.634413</td>\n",
       "      <td>6886.288452</td>\n",
       "      <td>0.225315</td>\n",
       "      <td>-282.297913</td>\n",
       "      <td>48.581680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829615</td>\n",
       "      <td>-6.066336</td>\n",
       "      <td>-4.167640</td>\n",
       "      <td>1.017302</td>\n",
       "      <td>-0.523806</td>\n",
       "      <td>0.538693</td>\n",
       "      <td>-8.855953</td>\n",
       "      <td>-2.927977</td>\n",
       "      <td>-1.118562</td>\n",
       "      <td>-5.906228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1PajbAKd8Kg_</th>\n",
       "      <td>0000_</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.407549</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>2710.811637</td>\n",
       "      <td>2664.287550</td>\n",
       "      <td>5778.474935</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>-346.857300</td>\n",
       "      <td>75.765617</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.838680</td>\n",
       "      <td>5.053118</td>\n",
       "      <td>-0.291308</td>\n",
       "      <td>0.987186</td>\n",
       "      <td>-2.447526</td>\n",
       "      <td>3.692367</td>\n",
       "      <td>2.312328</td>\n",
       "      <td>-2.059656</td>\n",
       "      <td>-4.772599</td>\n",
       "      <td>-0.503851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cov1</th>\n",
       "      <td>0.41269657015800476</td>\n",
       "      <td>0.059004</td>\n",
       "      <td>1555.648634</td>\n",
       "      <td>1418.599932</td>\n",
       "      <td>2870.737092</td>\n",
       "      <td>0.133998</td>\n",
       "      <td>-340.588013</td>\n",
       "      <td>104.156700</td>\n",
       "      <td>-32.228443</td>\n",
       "      <td>-13.615362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940006</td>\n",
       "      <td>-5.701087</td>\n",
       "      <td>-6.326630</td>\n",
       "      <td>-1.080040</td>\n",
       "      <td>-1.812609</td>\n",
       "      <td>-2.518986</td>\n",
       "      <td>-3.684266</td>\n",
       "      <td>-3.564146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-bZrDCS8KAg_</th>\n",
       "      <td>70000_</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>0.492974</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>1600.647469</td>\n",
       "      <td>2300.999728</td>\n",
       "      <td>3660.644531</td>\n",
       "      <td>0.047815</td>\n",
       "      <td>-543.776917</td>\n",
       "      <td>119.100296</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.675646</td>\n",
       "      <td>-1.250754</td>\n",
       "      <td>-2.634280</td>\n",
       "      <td>1.647435</td>\n",
       "      <td>0.647164</td>\n",
       "      <td>1.602689</td>\n",
       "      <td>-2.469729</td>\n",
       "      <td>0.704325</td>\n",
       "      <td>-5.352920</td>\n",
       "      <td>-1.281080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-ej81N6Aqo4_</th>\n",
       "      <td>0000_</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>0.400283</td>\n",
       "      <td>0.052132</td>\n",
       "      <td>2664.129566</td>\n",
       "      <td>2563.440387</td>\n",
       "      <td>5518.182373</td>\n",
       "      <td>0.121514</td>\n",
       "      <td>-290.840607</td>\n",
       "      <td>85.514404</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.843078</td>\n",
       "      <td>-4.629812</td>\n",
       "      <td>-7.424622</td>\n",
       "      <td>-4.511141</td>\n",
       "      <td>-7.482200</td>\n",
       "      <td>-4.865530</td>\n",
       "      <td>-6.353733</td>\n",
       "      <td>-5.024187</td>\n",
       "      <td>-8.422812</td>\n",
       "      <td>-0.831208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-gvLnl1smfs_</th>\n",
       "      <td>90000_</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.704281</td>\n",
       "      <td>0.058739</td>\n",
       "      <td>3090.031219</td>\n",
       "      <td>2740.856272</td>\n",
       "      <td>6530.841064</td>\n",
       "      <td>0.179077</td>\n",
       "      <td>-75.595451</td>\n",
       "      <td>68.849228</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.867559</td>\n",
       "      <td>0.677697</td>\n",
       "      <td>-7.535110</td>\n",
       "      <td>0.602187</td>\n",
       "      <td>-6.629556</td>\n",
       "      <td>0.659050</td>\n",
       "      <td>-4.125255</td>\n",
       "      <td>0.734950</td>\n",
       "      <td>-4.655417</td>\n",
       "      <td>-0.645009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-hu5q-Nn4BM_</th>\n",
       "      <td>70000_</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>0.424896</td>\n",
       "      <td>0.044159</td>\n",
       "      <td>3173.872023</td>\n",
       "      <td>2482.951387</td>\n",
       "      <td>5768.306478</td>\n",
       "      <td>0.221743</td>\n",
       "      <td>-264.064514</td>\n",
       "      <td>58.729767</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.354259</td>\n",
       "      <td>-0.625627</td>\n",
       "      <td>0.677355</td>\n",
       "      <td>-3.651989</td>\n",
       "      <td>-6.051376</td>\n",
       "      <td>1.211774</td>\n",
       "      <td>-14.923816</td>\n",
       "      <td>-11.180058</td>\n",
       "      <td>-8.861263</td>\n",
       "      <td>-5.078876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-jLQkyDhIxw_</th>\n",
       "      <td>10000_</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>0.434573</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>3006.457898</td>\n",
       "      <td>2270.008544</td>\n",
       "      <td>5383.550008</td>\n",
       "      <td>0.225385</td>\n",
       "      <td>-113.609337</td>\n",
       "      <td>61.575642</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.916544</td>\n",
       "      <td>1.918063</td>\n",
       "      <td>-8.441331</td>\n",
       "      <td>2.808456</td>\n",
       "      <td>-6.152548</td>\n",
       "      <td>-4.181546</td>\n",
       "      <td>-7.060247</td>\n",
       "      <td>-0.964895</td>\n",
       "      <td>0.560492</td>\n",
       "      <td>-1.245851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename    chroma_stft         rmse  \\\n",
       "0v8MGxNetjg_               10000_   20000.000000     0.519951   \n",
       "1j1duoxdxBg_               70000_   80000.000000     0.535472   \n",
       "1MSYO4wgiag_              120000_  130000.000000     0.496666   \n",
       "1PajbAKd8Kg_                0000_   10000.000000     0.407549   \n",
       "cov1          0.41269657015800476       0.059004  1555.648634   \n",
       "...                           ...            ...          ...   \n",
       "-bZrDCS8KAg_               70000_   80000.000000     0.492974   \n",
       "-ej81N6Aqo4_                0000_    8000.000000     0.400283   \n",
       "-gvLnl1smfs_               90000_  100000.000000     0.704281   \n",
       "-hu5q-Nn4BM_               70000_   80000.000000     0.424896   \n",
       "-jLQkyDhIxw_               10000_   20000.000000     0.434573   \n",
       "\n",
       "              spectral_centroid  spectral_bandwidth      rolloff  \\\n",
       "0v8MGxNetjg_           0.045853         1612.895795  1411.838677   \n",
       "1j1duoxdxBg_           0.001771         2892.087076  2467.408141   \n",
       "1MSYO4wgiag_           0.033657         3429.061935  2788.634413   \n",
       "1PajbAKd8Kg_           0.013452         2710.811637  2664.287550   \n",
       "cov1                1418.599932         2870.737092     0.133998   \n",
       "...                         ...                 ...          ...   \n",
       "-bZrDCS8KAg_           0.005093         1600.647469  2300.999728   \n",
       "-ej81N6Aqo4_           0.052132         2664.129566  2563.440387   \n",
       "-gvLnl1smfs_           0.058739         3090.031219  2740.856272   \n",
       "-hu5q-Nn4BM_           0.044159         3173.872023  2482.951387   \n",
       "-jLQkyDhIxw_           0.104041         3006.457898  2270.008544   \n",
       "\n",
       "              zero_crossing_rate       mfcc1       mfcc2       mfcc3  ...  \\\n",
       "0v8MGxNetjg_         2907.580566    0.107019 -376.876007  111.017372  ...   \n",
       "1j1duoxdxBg_         5072.664388    0.148584 -519.158447   60.781284  ...   \n",
       "1MSYO4wgiag_         6886.288452    0.225315 -282.297913   48.581680  ...   \n",
       "1PajbAKd8Kg_         5778.474935    0.142076 -346.857300   75.765617  ...   \n",
       "cov1                 -340.588013  104.156700  -32.228443  -13.615362  ...   \n",
       "...                          ...         ...         ...         ...  ...   \n",
       "-bZrDCS8KAg_         3660.644531    0.047815 -543.776917  119.100296  ...   \n",
       "-ej81N6Aqo4_         5518.182373    0.121514 -290.840607   85.514404  ...   \n",
       "-gvLnl1smfs_         6530.841064    0.179077  -75.595451   68.849228  ...   \n",
       "-hu5q-Nn4BM_         5768.306478    0.221743 -264.064514   58.729767  ...   \n",
       "-jLQkyDhIxw_         5383.550008    0.225385 -113.609337   61.575642  ...   \n",
       "\n",
       "                mfcc12    mfcc13    mfcc14    mfcc15    mfcc16    mfcc17  \\\n",
       "0v8MGxNetjg_ -0.656475 -7.439712 -1.034580 -0.203083 -3.513495 -1.745705   \n",
       "1j1duoxdxBg_ -0.156307 -0.909973  7.216461 -1.719629  3.903021  3.653039   \n",
       "1MSYO4wgiag_  0.829615 -6.066336 -4.167640  1.017302 -0.523806  0.538693   \n",
       "1PajbAKd8Kg_ -2.838680  5.053118 -0.291308  0.987186 -2.447526  3.692367   \n",
       "cov1          0.940006 -5.701087 -6.326630 -1.080040 -1.812609 -2.518986   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "-bZrDCS8KAg_ -2.675646 -1.250754 -2.634280  1.647435  0.647164  1.602689   \n",
       "-ej81N6Aqo4_ -8.843078 -4.629812 -7.424622 -4.511141 -7.482200 -4.865530   \n",
       "-gvLnl1smfs_ -6.867559  0.677697 -7.535110  0.602187 -6.629556  0.659050   \n",
       "-hu5q-Nn4BM_ -3.354259 -0.625627  0.677355 -3.651989 -6.051376  1.211774   \n",
       "-jLQkyDhIxw_ -8.916544  1.918063 -8.441331  2.808456 -6.152548 -4.181546   \n",
       "\n",
       "                 mfcc18     mfcc19    mfcc20     label  \n",
       "0v8MGxNetjg_  -3.011878  -2.878482 -2.106427 -4.026825  \n",
       "1j1duoxdxBg_   3.043882   2.439957  2.781968  2.195162  \n",
       "1MSYO4wgiag_  -8.855953  -2.927977 -1.118562 -5.906228  \n",
       "1PajbAKd8Kg_   2.312328  -2.059656 -4.772599 -0.503851  \n",
       "cov1          -3.684266  -3.564146       NaN       NaN  \n",
       "...                 ...        ...       ...       ...  \n",
       "-bZrDCS8KAg_  -2.469729   0.704325 -5.352920 -1.281080  \n",
       "-ej81N6Aqo4_  -6.353733  -5.024187 -8.422812 -0.831208  \n",
       "-gvLnl1smfs_  -4.125255   0.734950 -4.655417 -0.645009  \n",
       "-hu5q-Nn4BM_ -14.923816 -11.180058 -8.861263 -5.078876  \n",
       "-jLQkyDhIxw_  -7.060247  -0.964895  0.560492 -1.245851  \n",
       "\n",
       "[170 rows x 28 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('data/data_new_extended.csv')\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35c244a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "d = data1.drop(['filename','label'],axis=1)\n",
    "h = sns.heatmap(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59bc838e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "372301c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data1 = data1.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc396199",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data1.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c36595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data1.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bb3d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b2f271f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28758994, -0.3478334 , -0.35099591, ...,  0.98243227,\n",
       "        -1.40798036,  0.65523484],\n",
       "       [-0.22354755, -0.34822437, -0.35097655, ..., -1.63453015,\n",
       "        -1.67422902, -1.63924591],\n",
       "       [ 0.67094305, -0.34780793, -0.35099899, ...,  0.52941914,\n",
       "         0.52278956,  0.11991464],\n",
       "       ...,\n",
       "       [-0.59412223, -0.34792136, -0.35097261, ...,  0.34110886,\n",
       "         0.54303798,  0.29167731],\n",
       "       [-0.73468503, -0.34796061, -0.35102339, ..., -0.64290737,\n",
       "         0.56478156,  0.02234052],\n",
       "       [ 1.69321803, -0.3480218 , -0.35098855, ...,  1.80197436,\n",
       "        -0.40673473,  3.97283816]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "411622a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.3, input_shape=(60,)))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# serialize model to JSON\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model.json\", \"w\") as json_file:\n",
    "    #json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# plot model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1790623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               3456      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 12,373\n",
      "Trainable params: 12,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1d0155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0074\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136503f41f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "872d9b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
